# NVIDIA NIM Factory
This project is a factory for NVIDIA NIM containers in which users/businesses can quantize many models and build their own TensorRT-LLM engine for optimized inference. This enables users/businesses with large hardware resources but smaller business goals to save compute power by quantizing LLMs into different sizes. 

## Description
Optional section to provide a more detailed overview of the project.

## Getting Started
Optional section to summarize important steps and how to use the project & apps in the project

